{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 403 files belonging to 5 classes.\nUsing 323 files for training.\nFound 403 files belonging to 5 classes.\nUsing 80 files for validation.\n"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "image_size = (224, 224)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"training-data\",\n",
    "    validation_split=0.2,\n",
    "    label_mode='categorical',\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"training-data\",\n",
    "    validation_split=0.2,\n",
    "    label_mode='categorical',\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(int(labels[i]))\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda image, label: (tf.image.resize(image, image_size), label))\n",
    "val_ds = val_ds.map(lambda image, label: (tf.image.resize(image, image_size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<MapDataset shapes: ((None, 224, 224, 3), (None, 5)), types: (tf.float32, tf.float32)>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     first_image = images[1]\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         augmented_image = data_augmentation(\n",
    "#             tf.expand_dims(first_image, 0), training=True\n",
    "#         )\n",
    "#         plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "#         plt.title(int(labels[i]))\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "\n",
    "def create_model():\n",
    "    base_model = keras.applications.MobileNet(include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    inputs = keras.Input(shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    inputs = data_augmentation(inputs)\n",
    "    norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "    mean = np.array([127.5] * 3)\n",
    "    var = mean ** 2\n",
    "    # Scale inputs to [-1, +1]\n",
    "    inputs = norm_layer(inputs)\n",
    "    norm_layer.set_weights([mean, var])\n",
    "    \n",
    "    custom_model = base_model(inputs, training = False)\n",
    "    custom_model = keras.layers.GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = keras.layers.Dense(64, activation = 'relu')(custom_model)\n",
    "    custom_model = keras.layers.Dropout(0.5)(custom_model)\n",
    "    predictions = keras.layers.Dense(4, activation = 'softmax')(custom_model)\n",
    "    \n",
    "    return keras.Model(inputs = inputs, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "# import numpy as np\n",
    "\n",
    "# vgg_model = keras.applications.xception.Xception(weights = 'imagenet')\n",
    "\n",
    "# img_path = 'test_img/IMG_7503.JPG'\n",
    "# img = image.load_img(img_path, target_size=(299, 299))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# preds = vgg_model.predict(x)\n",
    "# # decode the results into a list of tuples (class, description, probability)\n",
    "# # (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n_________________________________________________________________\nsequential_2 (Sequential)    (None, 224, 224, 3)       0         \n_________________________________________________________________\nnormalization_1 (Normalizati (None, 224, 224, 3)       7         \n_________________________________________________________________\nxception (Functional)        (None, 7, 7, 2048)        20861480  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 10245     \n=================================================================\nTotal params: 20,871,732\nTrainable params: 10,245\nNon-trainable params: 20,861,487\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "# Pre-trained Xception weights requires that input be normalized\n",
    "# from (0, 255) to a range (-1., +1.), the normalization layer\n",
    "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
    "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "mean = np.array([127.5] * 3)\n",
    "var = mean ** 2\n",
    "# Scale inputs to [-1, +1]\n",
    "x = norm_layer(x)\n",
    "norm_layer.set_weights([mean, var])\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# x = keras.layers.Dense(64, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n6/6 [==============================] - 50s 8s/step - loss: 1.4030 - categorical_accuracy: 0.4675 - val_loss: 0.9557 - val_categorical_accuracy: 0.7500\nEpoch 2/15\n6/6 [==============================] - 51s 8s/step - loss: 0.9722 - categorical_accuracy: 0.7183 - val_loss: 0.6855 - val_categorical_accuracy: 0.8250\nEpoch 3/15\n6/6 [==============================] - 55s 9s/step - loss: 0.6679 - categorical_accuracy: 0.8390 - val_loss: 0.4921 - val_categorical_accuracy: 0.9125\nEpoch 4/15\n6/6 [==============================] - 50s 8s/step - loss: 0.5283 - categorical_accuracy: 0.9009 - val_loss: 0.3655 - val_categorical_accuracy: 0.9625\nEpoch 5/15\n6/6 [==============================] - 50s 8s/step - loss: 0.4114 - categorical_accuracy: 0.9443 - val_loss: 0.2933 - val_categorical_accuracy: 0.9750\nEpoch 6/15\n6/6 [==============================] - 52s 9s/step - loss: 0.3570 - categorical_accuracy: 0.9350 - val_loss: 0.2662 - val_categorical_accuracy: 0.9500\nEpoch 7/15\n6/6 [==============================] - 51s 8s/step - loss: 0.3290 - categorical_accuracy: 0.9505 - val_loss: 0.2253 - val_categorical_accuracy: 0.9750\nEpoch 8/15\n6/6 [==============================] - 50s 8s/step - loss: 0.2735 - categorical_accuracy: 0.9598 - val_loss: 0.2003 - val_categorical_accuracy: 0.9750\nEpoch 9/15\n6/6 [==============================] - 50s 8s/step - loss: 0.2533 - categorical_accuracy: 0.9350 - val_loss: 0.1763 - val_categorical_accuracy: 0.9750\nEpoch 10/15\n6/6 [==============================] - 58s 10s/step - loss: 0.2433 - categorical_accuracy: 0.9505 - val_loss: 0.1553 - val_categorical_accuracy: 0.9875\nEpoch 11/15\n6/6 [==============================] - 55s 9s/step - loss: 0.2210 - categorical_accuracy: 0.9567 - val_loss: 0.1412 - val_categorical_accuracy: 1.0000\nEpoch 12/15\n6/6 [==============================] - 49s 8s/step - loss: 0.2043 - categorical_accuracy: 0.9659 - val_loss: 0.1367 - val_categorical_accuracy: 1.0000\nEpoch 13/15\n6/6 [==============================] - 49s 8s/step - loss: 0.1934 - categorical_accuracy: 0.9628 - val_loss: 0.1350 - val_categorical_accuracy: 1.0000\nEpoch 14/15\n6/6 [==============================] - 52s 9s/step - loss: 0.1948 - categorical_accuracy: 0.9690 - val_loss: 0.1328 - val_categorical_accuracy: 1.0000\nEpoch 15/15\n6/6 [==============================] - 60s 10s/step - loss: 0.1652 - categorical_accuracy: 0.9783 - val_loss: 0.1347 - val_categorical_accuracy: 0.9750\n"
    }
   ],
   "source": [
    "# checkpoint = ModelCheckpoint(\"deka-view-classifier.h5\", monitor = 'val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "epochs = 15\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/deka-multiclassifier.X.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_labels = {\n",
    "    1: 'bedroom',\n",
    "    0: 'bathroom',\n",
    "    2: 'kitchen',\n",
    "    3: 'living-room',\n",
    "    4: 'view',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.00129035 0.00138375 0.00282763 0.00650656 0.98799175]]\nview\n"
    }
   ],
   "source": [
    "img_path = 'test_img/view.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "\n",
    "correct_pred = np.argmax(predictions)\n",
    "results = img_labels[correct_pred]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}